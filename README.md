# ğŸ›ï¸ Retail Sales Prediction with Random Forest

This project builds and evaluates various **Random Forest models** to predict retail sales based on time, holiday, and store-specific features. It includes preprocessing, model training with hyperparameter tuning, evaluation, and prediction on new datasets.

## ğŸ“‚ Files

- `csv_files/sales.csv` â€” Main dataset used for model training.
- `csv_files/ironkaggle_notarget.csv` â€” New data for predictions (without target).
- `csv_files/ironkaggle_solutions.csv` â€” Comparison/solution dataset.
- `models/` â€” Folder containing saved models (`.pkl` format).

## ğŸ§  Machine Learning Models

Three main Random Forest models were trained:

### âœ… `model_rf01`
- Features: All features except `sales`
- Normalization: `StandardScaler`
- Hyperparameters: `n_estimators=100`, `max_depth=20`
- Status: Trained and saved to `models/model_rf01.pkl`

### âœ… `model_rf02`
- Features: Dropped `open`, `is_weekend`, `school_holiday`, `year`
- Normalization: `StandardScaler`
- Hyperparameters: `n_estimators=100`, `max_depth=None`
- Status: Trained and saved to `models/model_rf02.pkl`

### âœ… `model_rf03`
- Grid Search (classification mistake â€” used `scoring='f1'`)
- Status: Trained, but improperly scored for regression

### âš™ï¸ HalvingGridSearchCV (Experimental)
- Feature engineering and time estimate logic for efficient hyperparameter search
- Output model: `models/best_rf_halving.pkl`
- Status: Time estimation and progress tracking using `tqdm` & `threading`

## ğŸ¤– Other Models Tried

Several other machine learning models were imported (e.g., `XBoost`, `GradientBoostingRegressor`, `lightgbm` etc.) and briefly tested. However, they performed significantly worse than Random Forest on this dataset.  
As a result, we removed their implementations to keep the project clean and focused on the best-performing model.

## ğŸ“Š Evaluation Metrics

Each model is evaluated using:
- **MAE**: Mean Absolute Error
- **RMSE**: Root Mean Squared Error
- **RÂ² Score**: Coefficient of Determination

## ğŸ” Feature Importance

Feature importances were plotted using `model.feature_importances_` to understand which variables most influence predictions.

## ğŸ“ˆ Correlation Matrix

A masked heatmap using `seaborn` highlights correlations between features.

## ğŸ“¤ Prediction on New Data

The file `ironkaggle_notarget.csv` was:
- Preprocessed with the same steps as training data
- Normalized using the previously fitted `StandardScaler`
- Predicted using `model_rf02`
- Output stored in `df01_with_predictions.csv`

## ğŸ› ï¸ Tools Used

- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `scikit-learn`: RandomForestRegressor, GridSearchCV, HalvingGridSearchCV
- `joblib`: For model saving/loading
- `tqdm` and `threading`: For progress monitoring

## ğŸ“ How to Run

1. Ensure required libraries are installed (`requirements.txt` or use `pip install -r requ

## ğŸ‘¥ Contributors

We welcome contributions from anyone interested in improving this project! Here are the current contributors:

* **Author**: JorgeMMLRodrigues
* **Email**: jorgemmlrodrigues@gmail.com
* **GitHub**: https://github.com/JorgeMMLRodrigues

* **Author**: Mic-dev-gif
* **Email**: michelemontalvo@outlook.com
* **GitHub**: https://github.com/Mic-dev-gif

* **Email**: simiatawane@gmail.com

* **Email**: felipe.rocha@ironhack.com
